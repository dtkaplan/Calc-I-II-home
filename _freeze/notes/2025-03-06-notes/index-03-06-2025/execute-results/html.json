{
  "hash": "02df0ac5ac2d2b790ef2136630a72f8a",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: DTK\ndate: 2025-03-06\nnumber-offset: 22\nformat: live-html\n---\n\n\n\n\n\n# 2025-03-06 class notes\n\nGo over the cylinder minimum area for a given volume.\n\n$$V(r, h) \\equiv \\pi r^2 h \\ \\ \\ \\text{and}\\ \\ \\ A(r, h) \\equiv 2 \\pi r^2 + 2 \\pi r h$$\n\nSet the volume for the cylinder and use that to find h as a function of $r$ that is $h = V^\\star / r^2$. \n\nPlug this into the formula for $A()$ to eliminate the $h$ dependence.\n\n$$A(r) = 2 \\pi r^2 + 2 V^\\star / r$$\n\n$A()$ has all the hallmarks of a function with an optimum. The first term grows with $r$, the second term gets smaller with $r$. \n\nThe process of optimizing: set $\\partial_r A(r) = 0$ and solve:\n\n$\\partial_r A(r) = 4 \\pi r - -2 V^\\star /r^2$. This gives\n\n$2 \\pi r_\\star - V^\\star /r^2_\\star = 0$ or, $r_\\star^3 = \\frac {V^\\star}{2\\pi}$.\n\n\n## Curvature at an argmax\n\nFind the second derivative and from that the curvature.\n\n$${\\cal K}_f(x)  \\equiv \\frac{\\left|\\partial_{xx} f(x)\\right|}{\\ \\ \\ \\ \\left|1 + \\left[\\strut\\partial_x f(x)\\right]^2\\right|^{3/2}}$$\n\nBut at the argmax, $\\partial_x f(x^\\star) = 0$ so the curvature is just \n$${\\cal K}_f(x^\\star) = \\left|\\strut\\partial_{xx} f(x^\\star)\\right|$$\nDraw the picture of the objective function with the little circle tucked under the maximum. \n\n## Newton Step\n\n\nMaximize $f(x)$\n\nFind zero of $g(x) \\equiv \\partial_x f(x)$.\n\nNewton step: $x_{n+1} = x_n - g(x_n) / g'(x_n)$\n\nOr, translated back to $f()$\n\nMove from current point by $-\\frac{\\partial_x f(x_n)}{\\partial_{xx}f(x_n)}$\n\nSort out what are units of this \"move by\" quantity.\n\nChapter 24.\n\n[Show Nelder-Mead animation](https://www.youtube.com/watch?v=j2gcuRVbwR0) \n\n## Maximum likelihood\n\nSetting: equipment failure. How long until items break? Let's give the probability of an item lasting $x$ time units.\n\nExponential PDF: $p(x) = \\lambda e^{-x \\lambda}$\n\nMost likely to break immediately (short lifetime) but a few will have extremely long lifetime. \n\n```{webr-r}\nslice_plot(L*exp(-x*L) ~ x, domain(x=0:20), L=1/10)\n```\n\n\nI measure $n$ examples, each lasts for $x_i$ time units.\n\nThe likelihood is the product of the individual PDFs. I know $x=x_i$, so the likelihood is a function of $\\lambda$. \n\nLikelihood: $$\\prod_{i=1}^n \\lambda e^{-\\lambda x_i}$$\n\nWant to find $\\lambda$ that maximizes this. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlikelihood <- function(lambda, x) {\n  prod(lambda * exp(-lambda*x))\n}\n\nobservations <- c(3,6,2,3,9)\n\nlikelihood(.5, x = observations)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.165654e-07\n```\n\n\n:::\n\n```{.r .cell-code}\nvlikelihood <- Vectorize(likelihood, \"lambda\")\n\nslice_plot(\n  vlikelihood(lambda, x=observations) ~ lambda, \n  domain(lambda = 0:1))\n```\n\n::: {.cell-output-display}\n![](index-03-06-2025_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nToo small. So let's look at the logarithm.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslice_plot(\n  log(vlikelihood(lambda, x=observations)) ~ lambda, \n  domain(lambda = 0:1))\n```\n\n::: {.cell-output-display}\n![](index-03-06-2025_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nSome statistical theory. Maximum likelihood estimation.\n\nIf $x_i$ are the values of $n$ observations, then the log-likelihood function is\n\n${\\cal L}(\\lambda) \\equiv n \\ln(\\lambda) - \\lambda \\sum x_i$\n\nWhere is the maximum? Differentiate and solve for zero.\n\n$$\\partial_\\lambda {\\cal L}(\\lambda) = \\frac{n}{\\lambda} -  \\sum x_i$$\nConsequently, $\\lambda^* = n / \\sum x_i$, the \"maximimum likelihood estimator.\n\n## Finding the variance through differentiation\n\nSuppose we have a normal probability distribution on $x$ with variance $\\sigma^2$:\n\n$$p(x) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\Large e^{- (x - m)^2/2\\sigma^2}$$\nGiven this curve, I want to find $\\sigma^2$. Here's one way:\n\n$$\\ln(p(x)) \\equiv - \\ln(2\\pi) -2 \\ln(\\sigma) - (x-m)^2/2\\sigma^2$$\n\nLet's look at $\\partial_x \\ln(p(x))$:\n\n$$\\partial_x \\ln(p(x)) \\equiv  -2 /\\sigma - 2 (x-m)/2\\sigma^2$$\n\nAnd now $\\partial_{xx} \\ln(p(x))$:\n\n$$\\partial_{xx} \\ln(p(x)) \\equiv  \\frac{1}{\\sigma^2}$$\nThat is, the radius at the argmax is $\\sigma^2$.\n\nSo, to find the variance of a distribution, take one over the second derivative of the logarithm of the distribution at the argmax.\n\nThe likelihood is proportional to a probability distribution. So let's find its variance. Then, we can translate that into a confidence interval, a range that will include 95% of the probability.\n\nIt will be based on the curvature, more specifically 2 times the square-root of the radius of the inscribed circle. \n\nHere's the curvature at the argmax\n\n$${\\cal K} = \\left|\\partial_{\\lambda\\lambda} {\\cal L}(\\lambda)\\right| = \\frac{n}{\\lambda^2}$$\nIn other words, the variance is $\\lambda^2 / n$ so the 95% confidence interval is $2 \\lambda / \\sqrt{n}$.\n\nWe have an estimator and its variance.\n\n\n",
    "supporting": [
      "index-03-06-2025_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}