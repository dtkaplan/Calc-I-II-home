{
  "hash": "adaa7d4b6fcdae8b9f227f6e4e0044b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: DTK\ndate: 2025-03-07\nnumber-offset: 23\nformat: live-html\n---\n\n\n\n\n\n# 2025-03-07 class notes\n\n## Partial derivative\n\nA derivative with respect to one variable, holding all the other variables constant. \"Constant\" is not necessarily zero. \n\n::: {.callout-note}\n## Moving this to 03-11 class\n\nExample, low-order polynomial in two variables:\n\n\n\n$$g(x, y) \\equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{xx} x^2 + a_{yy} y^2$$\n\n- Pick out two students to do $\\partial_x g(x, y)$ and $\\partial_y g(x,y)$\n- Pick out two students to do $\\partial_{xx} g(x, y)$ and $\\partial_{yy} g(x, y)$.\n- Pick out two students to do $\\partial_{xy} g(x, y)$ and $\\partial_{yx} g(x, y)$.\n\n$$\\partial_x g(x, y) = a_x + a_{xy} y + 2 a_{xx} x$$\n$$\\partial_y g(x, y) = a_y + a_{xy} x + 2 a_{yy} y$$\n\nA second-order polynomial in two inputs:\n```{webr-r}\nf <- makeFun(a0 + ax*x + ay*y + \n               axy*x*y + \n               axx*x^2 + ayy*y^2 ~ x & y,\n             a0 = \"a0\", ax = \"ax\", ay = \"ay\",\n             axy = \"axy\", axx = \"axx\", ayy = \"ayy\")\nD(f(x, y) ~ x)\nD(f(x, y) ~ y)\nD(f(x, y) ~ z)\nD(f(x, y) ~ x & x)\nD(f(x, y) ~ y & y)\nD(f(x, y) ~ x & y)\nD(f(x, y) ~ y & x)\n```\n\n\n\n\n```{webr-r}\nrrnorm <- function(n=1) {round(rnorm(n), 2)}\n\nmake_random_poly <- function(seed=NA) {\n  if (!is.na(seed)) set.seed(seed)\n  makeFun(a0 + ax*x + ay*y + axy*x*y + axx*x^2 + ayy*y^2 ~ x & y,\n          a0 = rrnorm(), ax = rrnorm(), ay = rrnorm(), \n          axy = rrnorm(),\n          axx = rrnorm(), ayy = rrnorm() )\n}\ng <- make_random_poly()\ncontour_plot(g(x, y) ~ x & y, domain(x=-1:1, y=-1:1))\n```\n\n```{webr-r}\ng\nD(g(x, y) ~ x)\nD(g(x, y) ~ y)\n```\n\nSecond-order partial derivatives\n```{webr-r}\nD(g(x, y) ~ x & x)\nD(g(x, y) ~ y & y)\nD(g(x, y) ~ x & y)\nD(g(x, y) ~ y & x)\n```\n:::\n\n\n## Gradient field\n\n```{webr-r}\nf <- doodle_fun(~ x + y, seed = 445)\ndom <- domain(x = -5:5, y = -5:5)\ncontour_plot(\n  f(x, y) ~ x & y, dom) |> \n  gf_refine(coord_fixed())\n```\n\n\n\n\nThe *gradient field* is a pair of functions on the $x, y$ space:\n\n```{webr-r}\n#| layout-ncol: 2\ng_x <- D(f(x, y) ~ x)\ng_y <- D(f(x, y) ~ y)\ncontour_plot(g_x(x, y) ~ x & y, dom) + coord_fixed()\ncontour_plot(g_y(x, y) ~ x & y, dom) + coord_fixed()\n```\n\nLet's show the zero contour of both partial derivatives on top of the function $f(x, y)$ itself.\n\n```{webr-r}\ncontour_plot(f(x, y) ~ x & y, dom) |>\ncontour_plot(g_x(x, y) ~ x & y, dom, \n             contours_at = 0, contour_color = \"red\") |>\ncontour_plot(g_y(x, y) ~ x & y, dom, \n             contours_at = 0, contour_color = \"magenta\") |>\n  gf_refine(coord_fixed())\n```\n\n```{webr-r}\ncontour_plot(f(x, y) ~ x & y, dom) |>\ngradient_plot(f(x, y) ~ x + y, dom) |>\n  gf_refine(coord_fixed())\n```\n\n## Gradient vector points in most steep direction\n\nImagine that we take a small step $(h_x, h_y)$ from an initial input point $(x_0, y_0)$. \n\nThe gradient vector is \n$$\\nabla f(x, y) \\equiv\\left({\\Large\\strut}\\partial_x f(x, y) ,\\ \\  \\partial_y f(x,y)\\right)$$ but to keep the notation compact, we'll write $\\nabla f(x,y) \\equiv (dx, dy)$.\n\nThe **total change** in the function output will be approximately \n$$h_x dx + h_y dy$$.\n\nWe want to pick $h_x$ and $h_y$ to make the increase as large as possible. But there needs to be some constraint, otherwise, we would just make the $h$'s big. So we will make it a unit length step, that is \n$$(h_x, h_y) = (h, \\sqrt{\\strut1 - h^2})$$\n\nThe total change is therefore\n$$\\Delta (h) \\equiv h\\  dx + \\sqrt{\\strut 1 - h^2}\\ dy$$\nWe want to maximize this with our choice of $h$. \n\n\n\n\nSet the derivative equal to zero:\n\n$$\\partial_h \\Delta (h) = 0 = dx - \\frac{h}{\\sqrt{\\strut 1 - h^2}}  dy$$\nor, \n$$\\frac{dx}{dy} = \\frac{h}{\\sqrt{\\strut 1-h^2}} = \\frac{h_x}{h_y}$$\n \nIn other words, we want $h_x$ to be proportional to $dx$ and $h_y$ to be likewise proportional to $dy$. \n\nThe direction to achieve the greatest increase in the value of $f()$ is the same as the direction of $\\nabla f(x, y)$.\n\nActivities from Ch. 25 exercises.\n\n\n",
    "supporting": [
      "index-03-07-2025_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}