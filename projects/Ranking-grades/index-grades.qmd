---
title: "Ranking by grade"
author: DTK
date: 2025-04-08
format: live-html
desc: "Applying a sports ranking method to the Registrar database"
categories: [linear algebra]
---


```{r include=FALSE}
library(LSTbook)
library(ggformula)
library(dplyr)
library(ggplot2)
library(tidyr)
library(LSTbook)
source("../../_software/software.R")
```
::: {.callout-tip collapse=true}
## Background software
```{webr-r}
#| autorun: true
#| context: setup
{{< include ../../_software/software.R >}}
```
:::

The task of this modeling project is to construct a ranking of students based on their grades over a college career.

The data come from a small college in the US Midwest. For reasons of anonymity, student names have been replace with unique meaningless ID codes, with all the courses taken by a student and the grades received identified by that student's code. Similarly, the instructor and department indentities are encoded. Also, only about half of the courses taken by each student are included. The students listed graduated in AY 2004/2005.

The data were originally in the form of three data frames in a relational database. We use data wrangling to merge them into a single data `Events` frame where the unit of observation is an event consisting of a single student receiving a grade in a single course.

```{r message=FALSE}
#| caption: Assembling the data
Events <- LSTbook::Grades |>
  left_join(LSTbook::Sessions) |>
  left_join(LSTbook::Gradepoint)
```

To orient you to the variables and their meanings, here are five randomly selected events:

```{r}
Events |> take_sample(n = 5)
```

The `gradepoint` variable is the numerical equivalent of the letter `grade`.

One oddity of the data is that, for a few students, courses were taken some years before the rest of the cohort. Let's wrangle up the distribution of semesters:

```{r}
Semesters <- Events |> 
  mutate(sem = gsub("S(1|2)", "SP", sem)) |>
  summarize(takers = n(), .by = sem) |>
  arrange(desc(takers)) |>
  mutate(keep = ifelse(takers > 400, "keep", "rid"))
Semesters
```

::: {.callout-note}
## For Statistical Modeling students

Join `Semesters` with `Events`. Use it to remove **students** who took any course outside of the most populated 8 semesters.

```{r}
#| caption: Remove underpopulated semester
Events |>
  left_join(Semesters |> select(sem, keep)) |>
  filter(keep == "keep") -> Goo
```

But really I want to remove *students*, not just the courses they took in off semesters.

```{r}
```{r}
#| caption: Remove underpopulated semester
Events |>
  left_join(Semesters |> select(sem, keep)) |>
  filter(all(keep == "keep"), .by = sid) -> Goo2
```
:::

## Ranking with GPA

Most students are familiar with the GPA and its use in ranking students. Here's the calculation written in the `{dplyr}` notation.

```{r}
GPA <- Events |>
  summarize(gpa_raw = mean(gradepoint, na.rm = TRUE), .by = sid)
GPA |> take_sample(n = 5)
```

To be statistically literate, such an estimate of the GPA should come with a confidence interval. We'll calculate the margin of error using stardard textbook formulas. In calculating the margin of error, I'll artificially *double* the $n$ for each student so that we get the magnitude of standard errors we would expect to see if we had *all* the student-grade records.

```{r}
GPA <- Events |>
  summarize(gpa_raw = mean(gradepoint, na.rm = TRUE), 
            gp_var = var(gradepoint, na.rm = TRUE),
            gp_me = 2 * sqrt(gp_var / 2 * n()),
            .lwr = gpa_raw - gp_me,
            .upr = gpa_raw + gp_me,
            .by = sid) |>
  select(sid, .lwr, gpa_raw, .upr)
GPA |> take_sample(n=5)
GPA |> 
  arrange(gpa_raw) |>
  mutate(rank = 1:n()) |>
  gf_segment(.lwr + .upr ~ rank + rank) |>
  gf_point(gpa_raw ~ rank, color = "red", size=0.1)
```

We can do much the same calculation by modeling, but we'll have to "adjust" the confidence intervals by hand to mimic data with the full collection of grades.

```{r}
GPA2 <- Events |> 
  model_train(gradepoint ~ sid) |>
  model_eval(data = tibble(sid = unique(Events$sid)), interval = "confidence") |>
  mutate(.lwr = .output - (.output - .lwr)/sqrt(2), .upr = .output + (.upr - .output)/sqrt(2))
set.seed(101)
GPA2 |>
  take_sample(n=5)
```

Compare GPA with GPA2:

```{r}
Compare <- GPA |> 
  select(sid, gpa_raw) |>
  mutate(gpa2 = GPA2$.output)
Compare |> point_plot(gpa_raw ~ gpa2)
```
::: {.callout-note}
## Why don't they ...?
Let's speculate on why registrars don't report a GPA with a confidence interval.
:::

## What about the covariates
TASK: Add in some covariates: semester, class level, class size

```{r}
GPA3 <- Events |> 
  model_train(gradepoint ~ sid + enroll + level + sem) |>
  model_eval(data = tibble(sid = unique(Events$sid), 
                           sem="SP2005", level=300, enroll=12), 
             interval = "confidence") |>
  mutate(.lwr = .output - (.output - .lwr)/sqrt(2), 
         .upr = .output + (.upr - .output)/sqrt(2))
set.seed(101)
GPA3 |>
  take_sample(n=5) |>
  select(sid, .lwr, .output, .upr)
```

```{r}
Compare <- Compare |>
  mutate(gpa3 = GPA3$.output)
```

Let's look at the extent to which `dept` or `instructor` plays a role:

```{r}
Events |> 
  model_train(gradepoint ~ enroll + level + sem + dept + iid + sid) |>
  anova_summary()
```

And find the "instructor-adjusted" GPA:
```{r}
GPA4 <- Events |> 
  model_train(gradepoint ~ sid + enroll + level + sem + dept) |>
  model_eval(data = tibble(sid = unique(Events$sid), 
                           sem="SP2005", level=300, enroll=12,
                           iid = "inst436", dept = "q"), 
             interval = "confidence") |>
  mutate(.lwr = .output - (.output - .lwr)/sqrt(2), 
         .upr = .output + (.upr - .output)/sqrt(2))
```

```{r}
Compare <- Compare |>
  mutate(gpa4 = GPA4$.output) |>
  mutate(r_gpa_raw = rank(gpa_raw),
         r_gpa3 = rank(gpa3),
         r_gpa4 = rank(gpa4))
```

How do the adjusted models agree with the "raw" gpa

```{r}
Compare |>
  point_plot(r_gpa3 ~ r_gpa_raw)
```

```{r}
Compare |>
  point_plot(r_gpa4 ~ r_gpa_raw)
```

How well do the two "adjusted" models agree?

```{r}
Compare |>
  point_plot(r_gpa3 ~ r_gpa4)
```


## A political problem

The registrar would never perform such a regression. The political heat from the faculty would be too great. 

Can we construct a ranking that uses only `sid`, `session`, and `gradepoint`? That will let us avoid




How many students did each instructor teach?

```{r}
#| label: grades-42s
nstudents <- Events |> 
  summarize(count = n(), .by = iid) |>
  arrange(desc(count))
```

Let's look only at instructors with more than 10 students.

```{r}
#| label: grades-42t
Keepers <-
  nstudents |>
  filter(count > 10) |>
  left_join(Events)
```

## Method

<https://maherou.github.io/Teaching/files/CS317/masseyMethod.pdf>

## Trying again

Compare all pairs of students in a session.

```{r}
for_one_session <- function(this_session) {
  Roster <- Events |> 
    filter(sessionID == this_session) |>
    select(sid, gradepoint)
  P1 <- expand.grid(Roster$sid, Roster$sid)
  P2 <- expand.grid(Roster$gradepoint, Roster$gradepoint)
  names(P1) <- c("sid", "sid2")
  names(P2) <- c("gp1", "gp2")
  dplyr::bind_cols(P1, P2) |> 
    mutate(gp3 = gp1 - gp2) |>
    filter(gp3 > 0) 
}

Sessions <- Events |> 
  select(sessionID, enroll) |>
  filter(enroll > 10) |>
  filter(row_number() == 1, .by = sessionID) 
Snames <- as.list(Sessions$sessionID)
```


```{r}
Rosters <- lapply(Snames, 
                  FUN = function(x) for_one_session(x)) |>
  dplyr::bind_rows() |> 
  mutate(sid = as.character(sid), sid2 = as.character(sid2)) |>
  mutate(competition = row_number())

student_index2 <- student_index <- 
  tibble::tibble(
    sid = unique(c(Rosters$sid, Rosters$sid2))) |>
  mutate(sindex = row_number())
names(student_index2) <- c("sid2", "sindex2")

Rosters <- Rosters |>
  left_join(student_index) |>
  left_join(student_index2)
```


## Fill in the matrix for each competition

```{r}
compete_M <- matrix(0, ncol = nrow(student_index), nrow = nrow(Rosters))
RC <- cbind(Rosters$competition, Rosters$sindex)
compete_M[RC] <- 1
RC2 <- cbind(Rosters$competition, Rosters$sindex2)
compete_M[RC2] <- -1
compete_M[nrow(compete_M), ] <- 1

# how many redundant vectors
table(svd(compete_M)$d > 0.01)
foo <- qr.solve(compete_M[,1:442], Rosters$gp3)

Rankings <- tibble::tibble(score = foo) |>
  bind_cols(student_index) |>
  mutate(rscore = rank(score)) |>
  arrange(desc(rscore)) |>
  left_join(GPA) |>
  select(sid, rscore, gpa_raw)

Rankings |> point_plot(rscore ~ gpa_raw)
```

Look at special cases, such as S31254 who had a perfect GPA but low rank in the class. Is this because s/he won competitions narrowly with students with a low rank.

```{r}
RR <- Rosters |> 
  left_join(Rankings) |> 
  left_join(Rankings, by = join_by(sid2  == sid))
RR |> filter(sid == "S31254") -> hoo
``` 


Or look at the two people with high rank but GPA near 3.0.

Compare the departments in which people of low rank took courses compared to high rank.


```{r}
Bottom <- Rankings |> filter(rscore < 100)
Low <- Events |>
  filter(sid %in% Bottom$sid) |>
  summarize(bottom_count = n(), .by = dept)
Top <- Rankings |> filter(rscore > 375) 
High <- Events |>
  filter(sid %in% Top$sid) |>
  summarize(top_count = n(), .by = dept)
Together <- Low |> full_join(High)
```

Look at `Together` to see whether students have the same distribution of departments.


## SAT scores and academic performance

The College Board claims that the predictive power of the SAT on (first-year) college performance corresponds to $r \approx 0.40$.

To visualize what this means, let's construct 10,000 pairs of SAT versus UATX performance that have this correlation and look at the rank of each student by both measures.

```{r}
n = 10000
Simulation <- tibble(
  common = 0.4 * rnorm(n),
  UATX = common + 0.47 * rnorm(n),
  SAT = common + 0.47 * rnorm(n)
)
Simulation |>
  model_train(UATX ~ SAT) |>
  R2()
Simulation |> point_plot(rank(UATX) ~ rank(SAT))
```

Perhaps a better intuition can be had by imagining 200 applicants and looking at the performace of those in the top half of the SAT versus those in the bottom half.

```{r}
Simulation |> 
  mutate(sat_position = ifelse(rank(SAT) > n/2, "top", "bottom")) |>
  take_sample(n = 200) |>
  point_plot(rank(UATX) ~ sat_position, annot = "model",
             point_ink = 0.5)
```

